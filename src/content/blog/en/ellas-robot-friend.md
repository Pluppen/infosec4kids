---
title: "Ella's Robot Friend - About AI Safety and Chatbots"
description: "Using AI tools safely and responsibly"
pubDate: "19 Mar 2025"
---
# Ella's Robot Friend - About AI Safety and Chatbots

"Wow, ChattyBot is so cool! It helped me with my math homework yesterday!"

Everyone turned toward Johan who was enthusiastically showing something on his new phone. It was recess, and several children gathered around him to look.

"What's ChattyBot?" asked Ella curiously, leaning forward to see better.

"It's an AI chatbot – that is, a robot that can talk to you and answer questions about anything," explained Johan proudly. "My older brother showed me it. It can write poems, answer questions, give tips... all sorts of things!"

"Cool!" exclaimed Sofia. "Can I try?"

Johan handed over the phone and Sofia typed: "What is the meaning of life?" Seconds later, a response came that made the children laugh.

"The meaning of life? Some say 42, others say ice cream. I think it's about being kind and having fun along the way. What do you think?" appeared on the screen.

The children took turns asking the chatbot questions. When it was Ella's turn, she took the phone and thought for a moment.

"Can you help me with my fact project about sea turtles?" she wrote.

ChattyBot quickly replied with several interesting facts about sea turtles and offered to help her write the entire project for her.

"It can do my homework!" exclaimed Ella in surprise.

"Yes, isn't that awesome?" said Johan. "My brother said many people in his class use it to write essays."

"But... isn't that cheating?" asked Li hesitantly.

Before anyone could answer, the school bell rang, and they hurried into the classroom. But Ella couldn't stop thinking about ChattyBot. After school, she downloaded the app to her own phone and began exploring.

She was fascinated by how the chatbot could answer almost all of her questions and how the conversations felt almost like talking to a real person. But after chatting for a while, she wrote: "What's my best friend's name?"

ChattyBot replied: "I'm sorry, I don't know what your best friend's name is, as you haven't told me that. I don't have access to personal information about you beyond what you share in our conversation."

Ella raised her eyebrows. This was interesting. She continued with more questions:

"Where do I live?"
"How old am I?"
"What's the name of my school?"

Each time, the chatbot kindly explained that it didn't have this information, and that it couldn't access personal details about her unless she shared them.

Ella thought about this. She decided to talk to Teacher Lisa the next day, to understand more about how these AI chatbots worked and how safe they were.

"Teacher Lisa, do you know what an AI chatbot is?" asked Ella after the morning assembly.

Teacher Lisa smiled. "Yes, that's actually a very current topic. We already planned a lesson on AI and security next week, but if you're interested, we can do it earlier. Have you encountered a chatbot?"

Ella told her about ChattyBot and how several children in the class had started using it for both entertainment and schoolwork.

"This sounds like a perfect opportunity to talk about both the possibilities and risks with AI," said Teacher Lisa. "Let's have that lesson tomorrow instead."

The next day, Teacher Lisa had invited Maya from the IT security team that the children knew from their previous DevOps project. Maya had brought her laptop and a small robot that could move and blink its eyes.

"Today we're going to talk about artificial intelligence, or AI, and especially about chatbots," Maya began. "Can anyone tell me what a chatbot is?"

"It's like a robot that you can chat with!" said Johan enthusiastically. "It answers questions and can help with homework and stuff."

"Good, Johan!" said Maya. "A chatbot is an AI program that is designed to have text conversations with humans. They can answer questions, give recommendations, tell stories, and much more."

Maya showed the little robot, which she called Blipp. "Blipp here is a physical robot, but it also has an AI that allows it to answer simple questions." She demonstrated by asking: "Blipp, what's the weather like today?"

Blipp blinked with its LED eyes and answered in a robot-like voice: "According to my latest update, it's 15 degrees and partly cloudy in our city today."

The children were impressed, but Ella noticed that Maya was looking at her laptop at the same time, and she guessed that Maya was actually controlling what Blipp said.

"Chatbots like ChattyBot are much more advanced than Blipp," continued Maya. "They use something called large language models, which have been trained on enormous amounts of text from the internet and books."

"Are they smart like humans?" asked Sofia.

"That's a good question," replied Maya. "They often seem smart because they can answer questions and write texts that resemble what humans would write. But they don't think like we do. They're more like advanced text completion systems. They predict which words should come next based on all the text they've been trained on."

"But they can lie sometimes!" said Li suddenly. "My dad asked a chatbot about something in his field of expertise, and it gave a completely wrong answer but sounded really confident."

"That's a very important observation, Li," said Maya. "AI chatbots can actually 'make things up', or as experts say, 'hallucinate'. They can give answers that sound convincing but are actually incorrect. That's why it's important to be critical and always double-check important information from other sources."

Teacher Lisa now took over and began talking about safety.

"There are some important things to consider when you use AI chatbots," she said and wrote points on the board:

1. **Personal Information** - Don't share personal details with chatbots, such as your full name, address, passwords, or other private information.

2. **Source Criticism** - Remember what we learned about source criticism. Always check important facts from chatbots with other reliable sources.

3. **Schoolwork** - Letting a chatbot do your entire schoolwork for you is not only cheating, it also prevents you from learning yourself.

4. **Inappropriate Content** - Some chatbots have filters to avoid inappropriate content, but they're not perfect. If a chatbot says something strange or uncomfortable, end the conversation and tell an adult.

5. **Dependency** - It's easy to become dependent on asking a chatbot instead of thinking for yourself. But your own brain is your most important tool!

"So we shouldn't use AI at all?" asked Johan, who seemed a bit disappointed.

"No, on the contrary!" said Maya. "AI can be wonderfully useful if you use it in the right way. Think of it as a tool, similar to a calculator. A calculator is good at quickly calculating difficult numbers, but you still need to understand the math yourself."

"Exactly," agreed Teacher Lisa. "AI can help you get ideas, learn new things, or understand complex topics. The smart thing is to use it as a helper, not as a replacement for your own thinking."

Ella thought about this and raised her hand. "So if I want to learn about sea turtles, I can ask the chatbot for facts, but then I need to write the project myself with my own words?"

"Perfect example, Ella!" said Maya. "And you can go a step further and confirm facts from other sources too, such as books or reliable websites. AI is good at helping you get started, but it doesn't replace your own research and understanding."

To make the lesson more interactive, Maya brought out a fun AI activity sheet where the children got to practice writing good, clear instructions to an AI. She explained that this is called "prompting" and that it's an important skill for getting useful answers from chatbots.

"AI chatbots are a bit like a genie in a bottle," explained Maya. "They give you what you ask for, but if you're not clear about what you want, you might not be happy with the result."

An example on the worksheet was:

Unclear question: "Give me info about the sun"
Clearer question: "Explain how our solar system works in a way that a 10-year-old would understand, focusing on the planets' movement around the sun."

The children worked in pairs to improve various unclear questions and had fun when they compared their improved versions.

At the end of the lesson, Teacher Lisa summarized the most important points:

"AI like chatbots are exciting tools that can help you learn and create, but remember to:
- Protect your personal information
- Be critical of the answers
- Use AI as a helper, not a replacement for your own thinking
- Tell an adult if you encounter something strange or inappropriate"

After school, Ella was full of new thoughts about AI. When she got home, she eagerly told her parents about the day's lesson.

"Mom, Dad, do you know what? AI chatbots are like helpful robots, but we need to be smart when we use them. They can actually 'hallucinate' – that is, make up things that aren't true!"

"That sounds like an interesting lesson," said her father. "I actually use an AI chatbot at work sometimes to help me write emails."

"Do you use it in a good or bad way?" asked Ella pointedly.

Her father laughed. "Hopefully in a good way! I use it to get ideas and improve my text, but I always write the final message myself and check all information."

Later that evening, Ella opened the ChattyBot app again. She thought about what Maya and Teacher Lisa had said about using AI in a smart way. She wrote:

"Hi ChattyBot! I'm working on a project about sea turtles. Can you give me three interesting facts about them, and suggest some good questions I can explore further on my own?"

ChattyBot replied with some fascinating facts about the turtles' navigation ability, their long lifespan, and their endangered status, followed by several interesting questions she could explore.

Ella smiled. This felt like a much better way to use the chatbot – as a starting point for her own research, not as someone who did the entire work for her.

"A good AI user is one who asks smart questions and thinks critically about the answers," Maya had said. And that was exactly what Ella intended to do.

She wrote in her notebook: "AI chatbots: Use as helpers, not replacements!" and drew a small robot with a light bulb beside it. Underneath she wrote: "My brain is still the best tool I have!"

During the following weeks, Teacher Lisa noticed that several of the children, including Ella, started using AI in a more thoughtful way. Instead of just asking the chatbots to do the entire work for them, they now asked questions that helped them understand topics better.

One day after school, Maya stopped by the classroom with some exciting news.

"Hello everyone! I just wanted to let you know that your work with AI safety has inspired other classes. The school management has now decided to create guidelines for the entire school on how AI can be used in a smart and safe way – and they want your help!"

The children became enthusiastic about the task. They worked together on a document that would become the school's official "AI Usage Guide." Ella, with all her experience of IT security, took the lead and helped organize the class's thoughts.

The final guide contained advice on:
- How to protect your personal information
- Thinking critically about AI-generated answers
- How AI can be used to help (not replace) learning
- What to do if you encounter inappropriate content
- How to write clear instructions to AI for better answers

The principal was so impressed with the guide that she decided the school would hold a special "AI Safety Day" where Ella and her classmates would teach other students about what they had learned.

At the parent meeting that term, Teacher Lisa proudly told the parents about how the class had developed in their thinking about digital technology.

"From ransomware to password security, from source criticism to AI safety – your children have learned so much about how to navigate safely in the digital world. But the most important thing is that they have learned to think critically and take responsibility for their digital activity."

One parent raised their hand. "But isn't all this technology a bit scary? Sometimes I feel like I don't even understand what my children are doing online."

Teacher Lisa nodded understandingly. "It can certainly feel that way. But think about this: your children are growing up in a world where digital technology is part of everyday life. By teaching them about safety and critical thinking now, we're preparing them to handle both today's and tomorrow's challenges."

On the way home from school one day, Ella thought about all the IT security lessons she had been part of during the year. From the first lesson about ransomware to the latest about AI chatbots – each lesson had given her a new "superhero power" to navigate safely in the digital world.

"You know what, Mom?" said Ella thoughtfully as they walked hand in hand. "I think the most important thing I've learned is to be curious but careful, to question things but also be open to new possibilities."

"That sounds like a good balance," replied her mother with a smile.

"And think how much I still have to learn!" continued Ella enthusiastically. "Technology changes all the time, so I need to keep learning new things about security."

"You'll do just fine," said her mother, squeezing her hand. "You're already an IT security expert compared to many adults I know!"

That night, before she fell asleep, Ella imagined the digital world as a big, exciting adventure. With all her new knowledge, she felt ready to explore it – cautiously but bravely, critically but curiously.

"Internet detective Ella," she whispered sleepily to herself. "Always on her mission to make the internet a little safer, one lesson at a time..."

With the thought of all the new adventures and discoveries waiting, Ella fell asleep with a smile on her lips, secure in the knowledge that she was well equipped for the digital future.
